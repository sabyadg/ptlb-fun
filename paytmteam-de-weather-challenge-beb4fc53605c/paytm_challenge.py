# -*- coding: utf-8 -*-
"""PayTM-Challenge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r_tm4ztt_rTbeUvKuOVgICdhI2Ori1kB
"""

# innstall java
!apt-get install openjdk-8-jdk-headless -qq > /dev/null

# install spark (change the version number if needed)
!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz

# unzip the spark file to the current folder
!tar xf spark-3.0.0-bin-hadoop3.2.tgz

# set your spark folder to your system path environment. 
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.0.0-bin-hadoop3.2"


# install findspark using pip
!pip install -q findspark

!pip install -q findspark

import findspark
findspark.init()

from pyspark.sql import SparkSession

spark = SparkSession.builder\
        .master("local")\
        .appName("Colab")\
        .config('spark.ui.port', '4050')\
        .getOrCreate()

spark

!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip
!unzip ngrok-stable-linux-amd64.zip
get_ipython().system_raw('./ngrok http 4050 &')
!curl -s http://localhost:4040/api/tunnels

"""# Solution

"""

from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql import Window
# Required for StructField, StringType, IntegerType, etc.
from pyspark.sql.types import *

csvCountrySchema = StructType([
      StructField("COUNTRY_ABBR", StringType(), False),
      StructField("COUNTRY_FULL", StringType(), False),
                                  ])

csvStationSchema = StructType([
        StructField("STN_NO", IntegerType(), False),
        StructField("COUNTRY_ABBR", StringType(), False)
                              ])
csvWeatherSchema = StructType([           
      StructField("STN_NO", IntegerType(), False),        
      StructField("WBAN", IntegerType(), False), 
      StructField("YEARMODA", IntegerType(), False), 
      StructField("TEMP", FloatType(), False),
      StructField("DEWP", FloatType(), False),
      StructField("SLP", FloatType(), False), 
      StructField("STP", FloatType(), False), 
      StructField("VISB", FloatType(), False), 
      StructField("WDSP", FloatType(), False),  
      StructField("MXSPD", FloatType(), False),
      StructField("GUST", FloatType(), False), 
      StructField("MAX", FloatType(), False),  
      StructField("MIN", FloatType(), False),  
      StructField("PRCP", FloatType(), False), 
      StructField("SNDP", FloatType(), False), 
      StructField("FRSHTT", IntegerType(), False)                                             
                                ])

                                 
        # A reference to our csv-seperated-file
csvCountryFile = "/content/data/countrylist.csv"
csvStationFile = "/content/data/stationlist.csv"
csvWeatherFile = "/content/data/2019/*.gz"

#Inputs
sdf_country = spark.read \
                .option('header', 'true') \
                .option('sep', ",") \
                .option("ignoreLeadingWhiteSpace", True) \
                .option("ignoreTrailingWhiteSpace", True) \
                .schema(csvCountrySchema)\
                .csv(csvCountryFile)    


sdf_station = spark.read \
                .option('header', 'true') \
                .option('sep', ",") \
                .option("ignoreLeadingWhiteSpace", True) \
                .option("ignoreTrailingWhiteSpace", True) \
                .schema(csvStationSchema)\
                .csv(csvStationFile) 


sdf_wthr19 = spark.read \
                .option("header", "true") \
                .schema(csvWeatherSchema)\
                .option("ignoreLeadingWhiteSpace", True) \
                .option("ignoreTrailingWhiteSpace", True) \
                .option('sep', ",") \
                .csv(csvWeatherFile) 

sdf_wthrstn19 =     sdf_station.join(sdf_country, on = 'COUNTRY_ABBR')  \
                             .join(sdf_wthr19, on = 'STN_NO')

sdf_wthrstn19.show()

sdf_wthrstn19.createOrReplaceTempView("wthr19");

"""Which Country had the hottest average temperature of the year """

spark.sql('''SELECT  COUNTRY_FULL, AVG(TEMP) AS AVG_TEMP FROM wthr19 WHERE TEMP != 9999.9 GROUP BY COUNTRY_FULL ORDER BY AVG(TEMP) DESC LIMIT 1''').show(1)

"""Found this interesting : https://www.amazon.com/Welcome-Djibouti-survive-hottest-country/dp/1794559418

Q) Which country has the second highest average mean wind speed over the year ?
"""

sdf_windspeed = spark.sql('''SELECT  COUNTRY_FULL, AVG(WDSP) AS AVG_TEMP FROM wthr19 WHERE WDSP != 9999.9 GROUP BY COUNTRY_FULL ORDER BY AVG(WDSP) DESC''') 
print(sdf_windspeed.collect()[1])

"""Q)Which country had the most consecutive days of tornades  funnel cloud formations ? 

---


"""

w1 = Window.partitionBy("COUNTRY_FULL").orderBy(["COUNTRY_FULL", "YEARMODA"])
w2 = Window.partitionBy("DIFF").orderBy("COUNTRY_FULL")

sdf_tornadoflag = spark.sql('''SELECT  COUNTRY_FULL,   YEARMODA , FRSHTT   , int(substring(string(FRSHTT),6,1)) AS `flag`
             FROM wthr19  WHERE  char_length(string(FRSHTT)) = 6   ORDER BY COUNTRY_FULL, YEARMODA DESC
                    ''')
sdf_tornadoflag = sdf_tornadoflag.withColumn("PREVIOUS_DAY", F.lag(sdf_tornadoflag.YEARMODA).over(w1)) 
sdf_tornadoflag = sdf_tornadoflag.withColumn("DIFF_DAY", F.when(F.isnull(sdf_tornadoflag.YEARMODA - sdf_tornadoflag.PREVIOUS_DAY), 0) \
                                  .otherwise(sdf_tornadoflag.YEARMODA - sdf_tornadoflag.PREVIOUS_DAY))\
                                  

sdf_tornadoflag.createOrReplaceTempView("tornadoflag");

spark.sql('''SELECT  * FROM tornadoflag WHERE flag =1  ORDER BY COUNTRY_FULL, YEARMODA''').show(50)





